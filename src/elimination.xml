<?xml version="1.0" encoding="UTF-8"?>

<!--********************************************************************
Copyright 2022 Dan Margalit and Joseph Rabinoff

Permission is granted to copy, distribute and/or modify this document
under the terms of the GNU Free Documentation License, Version 1.3 or
any later version published by the Free Software Foundation.  A copy of
the license is included in gfdl.xml.
*********************************************************************-->

<section xml:id="elimination">
  <title>The Elimination Method</title>

  <objectives>
    <ol>
      <li>Understand how to solve a system of equations using elimination and back-substitution.</li>
      <li>Learn how the elimination method corresponds to performing row operations on an augmented matrix.</li>
      <li><em>Vocabulary words:</em> <term>row operation,</term> <term>matrix equation,</term> <term>vector equation,</term> <term>augmented matrix,</term> <term>row equivalence.</term></li>
    </ol>
  </objectives>

  <introduction>
    <p>
      Consider the following system of three linear equations in three variables:
      <men xml:id="elimination-eg-1">
        \syseq{
          x_1 + 2x_2 + 3x_3 = 6;
          3x_1 + x_2 - x_3 = -2;
          2x_1 - 3x_2 + 2x_3 = 14\rlap.
        }
      </men>
      How do we solve this system?  You may have learned one or both of the following methods:
      <ul>
        <li>
          <alert>Substitution:</alert> Solve for <m>x_1</m> in terms of <m>x_2,x_3</m>, then substitute that expression for <m>x_1</m>.
        </li>
        <li>
          <alert>Elimination:</alert> Manipulate the equations to eliminate one of the variables from all but one equation.
        </li>
      </ul>
      It turns out that elimination scales better: when solving a system of thousands of equations in thousands of variables by computer, it is more efficient to use elimination than substitution.  In this section, we explain the idea behind the elimination method, and give the rules for performing elimination; in <xref ref="gauss-jordan"/> we will present a systematic algorithm solving a system of equations using elimination.
    </p>
  </introduction>

  <subsection>
    <title>
      The Idea of Elimination
    </title>

    <p>
      Let us solve the system <xref ref="elimination-eg-1"/> using elimination.  In order to eliminate <m>x_1</m> from the second equation, we subtract 3 times the first equation from the second:
      <me>
        \syseq{
          x_1 + 2x_2 + 3x_3 = 6;
          3x_1 + x_2 - x_3 = -2;
          2x_1 - 3x_2 + 2x_3 = 14\rlap.
        } \quad\xrightarrow{R_2 \minuseq 3R_1}\quad
        \syseq{
          x_1 + 2x_2 + 3x_3 = 6;
          \. - 5x_2 - 10x_3 = -20;
          2x_1 - 3x_2 + 2x_3 = 14\rlap.
        }
      </me>
      Here <m>R_i</m> means <q>the <m>i</m>th equation</q>; we use the letter <m>R</m> because it will soon refer to the <m>i</m>th row of a matrix.  The notation <m>R_2\minuseq 3R_1</m> means <q>replace the second equation by the second equation minus 3 times the first equation.</q>  Now we have <em>eliminated</em> <m>x_1</m> from the second equation.
    </p>

    <p>
      Next we eliminate <m>x_1</m> from the third equation by subtracting twice the first equation:
      <me>
        \syseq{
          x_1 + 2x_2 + 3x_3 = 6;
          \. - 5x_2 - 10x_3 = -20;
          2x_1 - 3x_2 + 2x_3 = 14\rlap.
        } \quad\xrightarrow{R_3\minuseq 2R_1}\quad
        \syseq{
          x_1 + 2x_2 + 3x_3 = 6;
          \. - 5x_2 - 10x_3 = -20;
          \. - 7x_2 - 4x_3 = 2\rlap.
        }
      </me>
      We have simplified our original system of equations: the second and third equations now form 2 equations in 2 variables.  Ignoring the first equation for the moment, we subtract <m>\frac 75</m> times the second from the third to eliminate <m>x_2</m> from the third equation:
      <me>
        \syseq{
          x_1 + 2x_2 + 3x_3 = 6;
          \. - 5x_2 - 10x_3 = -20;
          \. - 7x_2 - 4x_3 = 2\rlap.
        } \quad\xrightarrow{R_3 -= \frac57 R_2}\quad
        \syseq{
          x_1 + 2x_2 + 3x_3 = 6;
          \. - 5x_2 - 10x_3 = -20;
          \. \+ \. \+ 10x_3 = 30\rlap.
        }
      </me>
      The third equation now only has <em>one</em> variable: we have <term>isolated</term> <m>x_3</m> in this equation.
    </p>

    <p>
      <idx><h>Back-substitution</h></idx>
      We can solve our simplified system of equations by solving for <m>x_3</m>, then <m>x_2</m>, then <m>x_1</m>, in a process called <term>back-substitution</term>.   The third equation gives us a value for <m>x_3</m>:
      <me> 10x_3 = 30 \quad\implies\quad x_3 = 3.</me>
      Substituting <m>x_3=3</m> into the second equation produces one equation in one variable: we have now <em>isolated</em> <m>x_2</m>.  Solving for <m>x_2</m> gives
      <me> -5x_2 - 10(3) = -20 \quad\implies\quad x_2 = -2. </me>
      Finally, substituting <m>x_2=-2</m> and <m>x_3=3</m> into the first equation isolates <m>x_1</m>, and we have
      <me> x_1 + 2(-2) + 3(3) = 6 \quad\implies\quad x_1 = 1. </me>
      We have found our solution:
      <me> (x_1,x_2,x_3) = (1,-2,3). </me>
      We can verify that this is indeed a solution of our original system of equations <xref ref="elimination-eg-1"/> by substituting these values for the unknowns:
      <me>
        \syseq{
          x_1 + 2x_2 + 3x_3 = 6;
          3x_1 + x_2 - x_3 = -2;
          2x_1 - 3x_2 + 2x_3 = 14\rlap.
        } \quad\xrightarrow{\text{substitute}}\quad
        \syseq{
          (1) + 2(-2) + 3(3) = 6;
          3(1) + (-2) - (3) = -2;
          2(1) - 3(-2) + 2(3) = 14\rlap.
        } \qquad\bigcheck
      </me>

    </p>

    <note xml:id="isolate-all-vars">
      <p>
        The system of equations <xref ref="elimination-eg-1"/> has <em>only one solution</em> <m>(x_1,x_2,x_3) = (1,-2,3)</m> because we were able to <em>isolate</em> each of the three unknowns when performing back-substitution.  Indeed, the equation <m>10x_3=30</m> has only one solution <m>x_3=3</m>; the equation <m>-5x_2-10(3)=-20</m> has only one solution <m>x_2=-2</m>, and <m>x_1+2(-2)+3(3)=6</m> has only one solution <m>x_1=1</m>.
      </p>
    </note>

    <p>
      To perform elimination systematically, it is convenient to require that the first variable be isolated in the first equation, the second variable be isolated in the second equation, etc.  In order for this to happen, it may be necessary to reorder the equations.
    </p>

    <specialcase hide-type="true">
      <title>Reordering the Equations</title>
      <p>
        Let us solve the system of equations
        <me>
        \syseq{
          \. \+ 4x_2 + 3x_3 = 3;
          x_1 + x_2 - x_3 = 3;
          5x_1 - 3x_2 - 6x_3 = -6
        }
        </me>
        using elimination.  We could use the second equation to eliminate <m>x_1</m> from the third equation, but that would have the effect of isolating <m>x_1</m> in the second equation instead of the first.  To remedy this, we begin by interchanging the first two equations:
        <me>
        \syseq{
          \. \+ 4x_2 + 3x_3 = 3;
          x_1 + x_2 - x_3 = 3;
          5x_1 - 3x_2 - 6x_3 = -6
          } \quad\xrightarrow{R_1\longleftrightarrow R_2}\quad
        \syseq{
          x_1 + x_2 - x_3 = 3;
          \. \+ 4x_2 + 3x_3 = 3;
          5x_1 - 3x_2 - 6x_3 = -6\rlap.
        }
        </me>
        Now we eliminate <m>x_1</m> from the third equation:
        <me>
        \syseq{
          x_1 + x_2 - x_3 = 3;
          \. \+ 4x_2 + 3x_3 = 3;
          5x_1 - 3x_2 - 6x_3 = -6
        } \quad\xrightarrow{R_3\minuseq 5R_1}\quad
        \syseq{
          x_1 + x_2 - x_3 = 3;
          \. \+ 4x_2 + 3x_3 = 3;
          \. - 8x_2 - x_3 = -21
        }
        </me>
        and we eliminate <m>x_2</m> from the third equation by adding twice the second equation:
        <me>
        \syseq{
          x_1 + x_2 - x_3 = 3;
          \. \+ 4x_2 + 3x_3 = 3;
          \. - 8x_2 - x_3 = -21
        } \quad\xrightarrow{R_3\pluseq 2R_2}\quad
        \syseq{
          x_1 + x_2 - x_3 = 3;
          \. \+ 4x_2 + 3x_3 = 3;
          \. \+ \. \+ 5x_3 = -15\rlap.
        }
        </me>
      </p>
      <p>
        <idx><h>Back-substitution</h></idx>
        Now we solve the system using back-substitution. We have isolated <m>x_3</m> in the third equation, and we have
        <me> 5x_3 = -15 \quad\implies\quad x_3 = -3. </me>
        Substituting <m>x_3=-3</m> into the second equation isolates <m>x_2</m>:
        <me> 4x_2 + 3(-3) = 3 \quad\implies\quad x_2 = 3. </me>
        Finally, substituting <m>x_2=3</m> and <m>x_3=3</m> into the first equation isolates <m>x_1</m>:
        <me> x_1 + (3) - (-3) = 3 \quad\implies\quad x_1 = -3. </me>
        We have found our solution:
        <me> (x_1,x_2,x_3) = (-3,3,-3). </me>
        Let us check that we haven<rsq/>t made any mistakes by substituting these values into our original equation:
        <me>
        \syseq{
          \. \+ 4x_2 + 3x_3 = 3;
          x_1 + x_2 - x_3 = 3;
          5x_1 - 3x_2 - 6x_3 = -6
          } \quad\xrightarrow{\text{substitute}}\quad
        \syseq{
          \. \+ 4(3) + 3(-3) = 3;
          (-3) + (3) - (-3) = 3;
          5(-3) - 3(3) - 6(-3) = -6\rlap.
        } \qquad\bigcheck
        </me>
      </p>
      <p>
        Note that this system of equations again has only one solution, as we were able to isolate each of the three unknowns, as in this <xref ref="isolate-all-vars"/>.
      </p>
    </specialcase>

    <p>
      Both systems of equations we have considered so far have had only one solution.  Of course, this is not always the case.
    </p>

    <specialcase hide-type="true" xml:id="elimination-infty-solns">
      <title>Infinitely Many Solutions</title>
      <p>
        Condsider the system of equations
        <me>
        \syseq{
          x_1 + 2x_2 + 3x_3 = 1;
          4x_1 + 5x_2 + 6x_3 = 1;
          7x_1 + 8x_2 + 9x_3 = 1\rlap.
        }
        </me>
        Let us eliminate <m>x_1</m> from the second and third equations:
        <me>
        \syseq{
          x_1 + 2x_2 + 3x_3 = 1;
          4x_1 + 5x_2 + 6x_3 = 1;
          7x_1 + 8x_2 + 9x_3 = 1\rlap.
        } \quad\xrightarrow[R_3\minuseq 7R_1]{R_2 \minuseq 4R_1}\quad
        \syseq{
          x_1 + 2x_2 + 3x_3 = 1;
          \. - 3x_2 - 6x_3 = -3;
          \. - 6x_2 - 12x_3 = -6\rlap.
        }
        </me>
        When we subtract twice the second equation from the third in order to eliminate <m>x_2</m>, we end up eliminating <m>x_3</m> from the third equation as well:
        <me>
        \syseq{
          x_1 + 2x_2 + 3x_3 = 1;
          \. - 3x_2 - 6x_3 = -3;
          \. - 6x_2 - 12x_3 = -6
        } \quad\xrightarrow[R_3\minuseq 7R_1]{R_3 \minuseq 2R_2}\quad
        \syseq{
          x_1 + 2x_2 + 3x_3 = 1;
          \. - 3x_2 - 6x_3 = -3;
         \. \+ \. \+ 0 = 0\rlap.
        }
        </me>
        In this case, we were unable to isolate <m>x_3</m>, so we cannot solve for its value.  In fact, if we substitute <em>any</em> value for <m>x_3</m> into these equations, then we can solve for <m>x_2</m> and <m>x_1</m> using back-substitution.  For example, let us set <m>x_3=1</m>.  Now <m>x_2</m> is isolated in the second equation:
        <me> -3x_2 - 6(1) = -3 \quad\implies\quad x_2 = -1. </me>
        Substituting <m>x_2 = -1</m> and <m>x_3=1</m> into the first equation isolates <m>x_1</m>:
        <me> x_1 + 2(-1) + 3(1) = 1 \quad\implies\quad x_1 = 0. </me>
        We have found a solution <m>(x_1,x_2,x_3)=(0,-1,1)</m>, which we verify:
        <me>
        \syseq{
          x_1 + 2x_2 + 3x_3 = 1;
          4x_1 + 5x_2 + 6x_3 = 1;
          7x_1 + 8x_2 + 9x_3 = 1\rlap.
        } \quad\xrightarrow{\text{substitute}}\quad
        \syseq{
          (0) + 2(-1) + 3(1) = 1;
          4(0) + 5(-1) + 6(1) = 1;
          7(0) + 8(-1) + 9(1) = 1\rlap.
        } \qquad\bigcheck
        </me>
      </p>
      <p>
        This system of equations has <em>infinitely many solutions</em>.  In fact, we saw above that there is exactly one solution for any given value of <m>x_3</m>.  We will discuss this situation in detail in <xref ref="parametric-form"/>.
      </p>
    </specialcase>

    <specialcase hide-type="true" xml:id="elimination-no-solns">
      <title>Zero Solutions</title>
      <p>
        We slightly modify the previous <xref ref="elimination-infty-solns"/> to obtain the system
        <me>
        \syseq{
          x_1 + 2x_2 + 3x_3 = 1;
          4x_1 + 5x_2 + 6x_3 = 1;
          7x_1 + 8x_2 + 9x_3 = 2\rlap.
        }
        </me>
        Eliminating <m>x_1</m> from the second and third equations gives:
        <me>
        \syseq{
          x_1 + 2x_2 + 3x_3 = 1;
          4x_1 + 5x_2 + 6x_3 = 1;
          7x_1 + 8x_2 + 9x_3 = 2
        } \quad\xrightarrow[R_3\minuseq 7R_1]{R_2 \minuseq 4R_1}\quad
        \syseq{
          x_1 + 2x_2 + 3x_3 = 1;
          \. - 3x_2 - 6x_3 = -3;
          \. - 6x_2 - 12x_3 = -5\rlap.
        }
        </me>
        Now we subtract twice the second equation from the third in order to eliminate <m>x_2</m>:
        <me>
        \syseq{
          x_1 + 2x_2 + 3x_3 = 1;
          \. - 3x_2 - 6x_3 = -3;
          \. - 6x_2 - 12x_3 = -5
        } \quad\xrightarrow[R_3\minuseq 7R_1]{R_3 \minuseq 2R_2}\quad
        \syseq{
          x_1 + 2x_2 + 3x_3 = 1;
          \. - 3x_2 - 6x_3 = -3;
         \. \+ \. \+ 0 = 1\rlap.
        }
        </me>
        Of course, there are no values of <m>x_1,x_2,x_3</m> that will make the equation <m>0=1</m> true, so we have found that this system has <em>no solutions</em>.  (Geometrically, the equations <m>-3x_2 - 6x_3 = -3</m> and <m>-6x_2-12x_3=-5</m> define parallel planes.)
      </p>
    </specialcase>

  </subsection>

  <subsection>
    <title>Row Operations</title>

    <p>
      In the discussion above, we manipulated a system of equations in two different ways: we added a multiple of one equation to another (<m>R_i \pluseq cR_j</m>), and we interchanged two equations (<m>R_i\longleftrightarrow R_j</m>).  We allow ourselves one additional operation, namely, multiplying both sides of an equation by a nonzero scaler (<m>R_i\timeseq c</m>).  These three operations form the manipulations that we will allow in our elimination algorithms.
    </p>

    <definition>
      <title>Row Operations</title>
      <idx><h>Row operations</h><h>definition of</h></idx>
      <idx><h>Row replacement</h></idx>
      <notation><usage>R_i\pluseq R_j</usage><description>Row replacement</description></notation>
      <notation><usage>R_i\longleftrightarrow R_j</usage><description>Row swap</description></notation>
      <notation><usage>R_i\timeseq c</usage><description>Row scaling</description></notation>
      <statement>
        <p>
          The following three operations on a system of equations are called <term>row operations</term>.
          <ul>
            <li>
              <alert>Row Replacement:</alert> We can add a multiple of equation <m>j</m> to equation <m>i</m>, replacing equation <m>i</m> with the result (here <m>i\neq j</m>).  Notation: <m>R_i \mathrel{\pm}= cR_j</m>.
              <me>
                \def\r{\textcolor{seq-red}}
                \syseq{
                  x_1 + 2x_2 + 3x_3 = 6;
                  3x_1 + x_2 - x_3 = -2;
                  2x_1 - 3x_2 + 2x_3 = 14
                } \quad\xrightarrow{R_3\minuseq 2R_1}\quad
                \syseq{
                  x_1 + 2x_2 + 3x_3 = 6;
                  3x_1 + x_2 - x_3 = -2;
                  \. \mathbin{\r-} \r{7x_2} \mathbin{\r-} \r{4x_3}, \mathbin{\r=} \r2\rlap.
                }
              </me>
            </li>
            <li>
              <alert>Row Swap:</alert> We can interchange equations <m>i</m> and <m>j</m>.  Notation: <m>R_i \longleftrightarrow R_j</m>.
              <me>
                \def\r{\textcolor{seq-red}}
                \syseq{
                  x_1 + 2x_2 + 3x_3 = 6;
                  3x_1 + x_2 - x_3 = -2;
                  2x_1 - 3x_2 + 2x_3 = 14;
                } \quad\xrightarrow{R_1\longleftrightarrow R_2}\quad
                \syseq{
                  \r{3x_1} \mathbin{\r+} \r{x_2} \mathbin{\r-} \r{x_3} \mathbin{\r=} \r{-2};
                  \r{x_1} \mathbin{\r+} \r{2x_2} \mathbin{\r+} \r{3x_3} \mathbin{\r=} \r6;
                  2x_1 - 3x_2 + 2x_3 = 14\rlap.
                }
              </me>
            </li>
            <li>
              <alert>Row Scaling:</alert> We can multiply both sides of an equation by a nonzero scalar <m>c</m>.  Notation: <m>R_i \timeseq c</m> or <m>R_i \diveq c</m>.
              <me>
                \def\r{\textcolor{seq-red}}
                \syseq{
                  x_1 + 2x_2 + 3x_3 = 6;
                  3x_1 + x_2 - x_3 = -2;
                  2x_1 - 3x_2 + 2x_3 = 14
                } \quad\xrightarrow{R_1\timeseq 2}\quad
                \syseq{
                  \r{2x_1} \mathbin{\r+} \r{4x_2} \mathbin{\r+} \r{6x_3} \mathbin{\r=} \r{12};
                  3x_1 + x_2 - x_3 = -2;
                  2x_1 - 3x_2 + 2x_3 = 14\rlap.
                }
              </me>
            </li>
          </ul>
        </p>
      </statement>
    </definition>

    <p>
      If <m>(x_1,x_2,x_3)</m> is a solution of a system of equations, then it remains a solution after performing a row operation on that system.  For instance, we saw that <m>(x_1,x_2,x_3) = (1,-2,3)</m> is a solution of the system of equations
      <me>
        \syseq{
          x_1 + 2x_2 + 3x_3 = 6;
          3x_1 + x_2 - x_3 = -2;
          2x_1 - 3x_2 + 2x_3 = 14\rlap.
        }
      </me>
      This means that, after substituting <m>(x_1,x_2,x_3) = (1,-2,3)</m> into these equations, we obtain the equalities
      <me>
        \syseq{6 = 6; -2 = -2; 14 = 14\rlap.}
      </me>
      If we perform the row operation <m>R_3\minuseq 2R_1</m> on this system, then
      <me>
        \syseq{
          x_1 + 2x_2 + 3x_3 = 6;
          3x_1 + x_2 - x_3 = -2;
          2x_1 - 3x_2 + 2x_3 = 14
        } \quad\xrightarrow{R_3\minuseq 2R_1}\quad
        \syseq{
          x_1 + 2x_2 + 3x_3 = 6;
          3x_1 + x_2 - x_3 = -2;
          \. - 7x_2 - 4x_3 = 2\rlap.
        }
      </me>
      becomes
      <me>
        \syseq{6 = 6; -2 = -2; 14 = 14}
        \quad\xrightarrow{R_3\minuseq 2R_1}\quad
        \syseq{6 = 6; -2 = -2; 2 = 2}
      </me>
      after substituting the values of the variables.  In other words, <m>(x_1,x_2,x_3) = (1,-2,3)</m> is a solution of the new system as well.
    </p>

    <note hide-type="true" xml:id="row-ops-are-reversible">
      <title>Fact</title>
      <p>
        All three row operations are <em>reversible</em>.
        <ul>
          <li>
            <m>R_i\minuseq R_j</m> undoes <m>R_i\pluseq R_j</m>.
          </li>
          <li>
            <m>R_i\longleftrightarrow R_j</m> undoes itself.
          </li>
          <li>
            <m>R_i\diveq c</m> undoes <m>R_i\timeseq c</m> (recall that <m>c\neq 0</m>).
          </li>
        </ul>
      </p>
    </note>

    <p>
      It follows from reversibility that if <m>(x_1,x_2,x_3)</m> is a solution of a system of equations <em>after</em> performing a row operation, then it is also a solution <em>before</em> performing the row operation.  In other words:
    </p>

    <proposition xml:id="row-ops-same-soln-set">
      <statement>
        <p>
          Performing a row operation on a system of equations does not change its solution set.
        </p>
      </statement>
    </proposition>

    <p>
      Of course, this is the whole point: in order to solve a system of equations, we use row operations to change it into a simpler system <em>with the same solutions</em>.  In diagram form:
        <latex-code>
            <![CDATA[
    \begin{tikzpicture}
      \node[align=center] (A) at (0,0) {system\\of\\equations};
      \draw[thick] (A.south west) to[bend left=30, looseness=0.5] (A.north west);
      \draw[thick] (A.south east) to[bend right=30, looseness=0.5] (A.north east);
      \node[align=center, right=4cm of A] (B) {(simpler)\\system\\of\\equations};
      \draw[thick] (B.south west) to[bend left=30, looseness=0.5] (B.north west);
      \draw[thick] (B.south east) to[bend right=30, looseness=0.5] (B.north east);
      \draw[thick, shorten=5mm, ->] (A.east) to["row", "operations"'] (B.west);
      \coordinate (C) at ($(A.south) - (0,1.2cm)$);
      \draw[very thick, seq-orange, <-] (A.south) -- (C);
      \draw[very thick, seq-orange, ->] (C) to["SAME", "SOLUTIONS"'] (C -| B.south) -- (B.south);
    \end{tikzpicture}
            ]]>
        </latex-code>
    </p>

  </subsection>

  <subsection>
    <title>From Systems of Equations to Matrices</title>

    <p>
      When performing row operations on a system of equations like
      <me>
        \syseq{
          x_1 + 2x_2 + 3x_3 = 6;
          3x_1 + x_2 - x_3 = -2;
          2x_1 - 3x_2 + 2x_3 = 14{\rlap,}
        }
      </me>
      only the <em>coefficients</em> of the unknowns change; the variables themselves stay exactly where they are.  In that sense, the variables are just placeholders, so it is more efficient to extract the numbers from the system and put them in a box, like so:
      <me>
        \amat{
          1 2 3 6;
          3 1 -1 -2;
          2 -3 2 14
        }.
      </me>
      Moreover, it is easy for a computer to understand a box full of numbers (a two-dimensional array of floating point values), whereas the concept of an <q>unknown</q> or a <q>solution</q> is much more abstract.  For these reasons, we will rewrite our equations using matrices.  We will also write them using vectors; this viewpoint will be important starting in <xref ref="spans"/>.
    </p>

    <definition hide-type="true" xml:id="defn-four-ways">
      <title>Four Ways to Write a System of Equations</title>
      <idx><h>Matrix equation</h></idx>
      <idx><h>Vector equation</h></idx>
      <idx><h>Coefficient matrix</h></idx>
      <idx><h>Augmented matrix</h></idx>
      <statement>
        <p>
          We can write a system of equations in the following equivalent ways.
          <ul>
            <li>
              As a <term>system of equations</term>:
              <me>
                \def\r{\textcolor{seq-red}}
                \def\g{\textcolor{seq-green}}
                \def\b{\textcolor{seq-blue}}
                \def\p{\textcolor{seq-violet}}
                \syseq{
                  \r1x_1 + \g2x_2 + \b3x_3 = \p6;
                  \r3x_1 + \g1x_2 \mathbin{\b-} \b1x_3 = \p{-2}{\rlap.}
                }
              </me>
            </li>
            <li>
              As a <term>matrix equation</term> <m>Ax=b</m>:
              <me>
                \def\r{\textcolor{seq-red}}
                \def\g{\textcolor{seq-green}}
                \def\b{\textcolor{seq-blue}}
                \def\p{\textcolor{seq-violet}}
                \mat{
                  \r1 \g2 \b3;
                  \r3 \g1 \b{-1}
                }\vec{x_1 x_2 x_3} = \vec{\p6 \p{-2}}.
              </me>
              The matrix
              <me> A = \mat{1 2 3; 3 1 -1} </me>
              is called the <term>coefficient matrix</term>: it holds the <em>coefficients</em> of the unknowns in the system of equations.  The vector <m>x=(x_1,x_2,x_3)</m> contains the unknowns, and the vector <m>b=(6,-2)</m> contains the constants on the right side of the equation.
            </li>
            <li>
              As a <term>vector equation</term>:
              <me>
                \def\r{\textcolor{seq-red}}
                \def\g{\textcolor{seq-green}}
                \def\b{\textcolor{seq-blue}}
                \def\p{\textcolor{seq-violet}}
                x_1\vec{\r1 \r3} + x_2\vec{\g2 \g1} + x_3\vec{\b3 \b{-1}} = \vec{\p6 \p{-2}}.
              </me>
              Note that the vectors on the right side of the equation are the columns of the coefficient matrix.
            </li>
            <li>
              As an <term>augmented matrix</term> <m>\amat{A b}</m>:
              <me>
                \def\r{\textcolor{seq-red}}
                \def\g{\textcolor{seq-green}}
                \def\b{\textcolor{seq-blue}}
                \def\p{\textcolor{seq-violet}}
                \amat{
                  \r1 \g2 \b3 \p6;
                  \r3 \g1 \b{-1} \p{-2}
                }.
              </me>
              This is a notational convenience: it is a matrix formed by joining the coefficient matrix <m>A</m> and the constant vector <m>b</m> together with a line between them.
            </li>
          </ul>
        </p>
      </statement>
    </definition>

    <p>
      Expanding out the matrix-vector product <m>Ax</m> in <m>Ax=b</m> yields
      <me>
        \mat{
          1 2 3;
          3 1 {-1}
        }\vec{x_1 x_2 x_3} = \vec{6 {-2}}
        \quad\xrightarrow{\text{becomes}}\quad
        \vec{
          1x_1+2x_2+3x_3
          3x_1+1x_2-1x_3
        } = \vec{6 -2}.
      </me>
      Since two vectors are <xref ref="vector-equality-defn" text="title">equal</xref> if and only if they have the same size and the same coordinates, this is equivalent to the original system of equations
      <me>
        \syseq{
          x_1 + 2x_2 + 3x_3 = 6;
          3x_1 + x_2 - x_3 = -2\rlap.
        }
      </me>
      Using the <q>by columns</q> approach to <xref ref="matrix-vector-product" text="title">matrix-vector multiplication</xref>, we see that a matrix equation is equivalent to a vector equation:
      <me>
        \mat{
          1 2 3;
          3 1 {-1}
        }\vec{x_1 x_2 x_3} = \vec{6 {-2}} \quad\iff\quad
        x_1\vec{1 3} + x_2\vec{2 1} + x_3\vec{3 -1} = \vec{6 -2}.
      </me>
    </p>

    <p>
      When writing a system of equations as a matrix equation <m>Ax=b</m>:
      <me>
        \syseq{x_1 + 2x_2 + 3x_3 = 6; 3x_1 + x_2 - x_3 = -2}
        \quad\xrightarrow{\text{becomes}}\quad
        \mat{
          1 2 3;
          3 1 {-1}
        }\vec{x_1 x_2 x_3} = \vec{6 {-2}},
      </me>
      the coefficient matrix <m>A</m> has 2 rows and 3 columns, the constant vector <m>b</m> has size 2, and the unknown vector <m>x</m> has size 3.  Each row of <m>A</m> (resp. coordinate of <m>b</m>) comes from the left (resp. right) side of one of the equations we started with, and each column of <m>A</m> and coordinate of <m>x</m> comes from one of the unknowns.
    </p>

    <bluebox>
      <title>The Sizes in a Matrix Equation</title>
      <p>
        <latex-code mode="bare">
          \def\r{\textcolor{seq-red}}
          \def\b{\textcolor{seq-blue}}
        </latex-code>
        In the matrix equation <m>Ax=b</m>, the matrix <m>A</m> has size <m>\r m\times\b n</m>, the unknown vector <m>x</m> has size <m>\b n</m>, and the constant vector <m>b</m> has size <m>\r m</m>, where:
        <ul>
          <li>
            <m>\textcolor{seq-red}m</m> is the <em>number of equations</em>, and
          </li>
          <li>
            <m>\textcolor{seq-blue}n</m> is the <em>number of unknowns</em>.
          </li>
        </ul>
      </p>
    </bluebox>

    <p>
      Since row operations really only act on the coefficients of the variables and on the constants in a system of equations, augmented matrices are well-suited to performing row operations, both by hand and by computer.  In terms of augmented matrices, the row operations become:
    </p>

    <definition>
      <title>Row Operations: Augmented Matrix Form</title>
      <idx><h>Row operations</h><h>definition of</h></idx>
      <idx><h>Row replacement</h></idx>
      <statement>
        <p>
          The following three operations on an augmented matrix are called <term>row operations</term>.
          <ul>
            <li>
              <alert>Row Replacement:</alert> We can add a multiple of row <m>j</m> to row <m>i</m>, replacing row <m>i</m> with the result.
              <me>
                \def\r{\textcolor{seq-red}}
                \amat{1 2 3 6; 3 1 -1 -2; 2 -3 2 14}
                \quad\xrightarrow{R_3\minuseq 2R_1}\quad
                \amat{1 2 3 6; 3 1 -1 -2; \r0 \r{-7} \r{-4} \r2}.
              </me>
            </li>
            <li>
              <alert>Row Swap:</alert> We can interchange two rows.
              <me>
                \def\r{\textcolor{seq-red}}
                \amat{1 2 3 6; 3 1 -1 -2; 2 -3 2 14}
                \quad\xrightarrow{R_1\longleftrightarrow R_2}\quad
                \amat{\r3 \r1 \r{-1} \r{-2}; \r1 \r2 \r3 \r6; 2 -3 2 14}.
              </me>
            </li>
            <li>
              <alert>Row Scaling:</alert> We can multiply a row by a nonzero scalar.
              <me>
                \def\r{\textcolor{seq-red}}
                \amat{1 2 3 6; 3 1 -1 -2; 2 -3 2 14}
                \quad\xrightarrow{R_1\timeseq 2}\quad
                \amat{\r2 \r4 \r6 \r{12}; 3 1 -1 -2; 2 -3 2 14}.
              </me>
            </li>
          </ul>
        </p>
      </statement>
    </definition>

    <p>
      Eliminating a variable from an equation now corresponds to generating a zero entry in an augmented matrix.  For example,
      <me>
        \syseq{
          x_1 + 2x_2 + 3x_3 = 6;
          3x_1 + x_2 - x_3 = -2;
          2x_1 - 3x_2 + 2x_3 = 14\rlap.
        } \quad\xrightarrow{R_2 \minuseq 3R_1}\quad
        \syseq{
          x_1 + 2x_2 + 3x_3 = 6;
          \. - 5x_2 - 10x_3 = -20;
          2x_1 - 3x_2 + 2x_3 = 14\rlap.
        }
      </me>
      becomes
      <me>
        \amat{
          1 2 3 6;
          3 1 -1 -2;
          2 -3 2 14
        } \quad\xrightarrow{R_2 \minuseq 3R_1}\quad
        \amat{
          1 2 3 6;
          \textcolor{seq-red}0 -5 -10 -20;
          2 -3 2 14
        }.
      </me>
      With this in mind, we can perform elimination on augmented matrices exactly as on systems of equations.
    </p>

    <example xml:id="elimination-eg-1-amat">
      <p>
        Let us solve the system of equations <xref ref="elimination-eg-1"/> again, this time using row operations on augmented matrices.  First we translate the system into an augmented matrix:
        <me>
          \syseq{
            x_1 + 2x_2 + 3x_3 = 6;
            3x_1 + x_2 - x_3 = -2;
            2x_1 - 3x_2 + 2x_3 = 14
          }\quad\xrightarrow{\text{becomes}}\quad
          \amat{
            1 2 3 6;
            3 1 -1 -2;
            2 -3 2 14
          }.
        </me>
        We eliminate <m>x_1</m> from the second and third equations:
        <me>
          \amat{
            1 2 3 6;
            3 1 -1 -2;
            2 -3 2 14
          } \quad\xrightarrow[R_3\minuseq 2R_1]{R_2\minuseq 3R_1}\quad
          \amat{
            1 2 3 6;
            \textcolor{seq-red}0 -5 -10 -20;
            \textcolor{seq-red}0 -7 -4 2
          }.
        </me>
        Now we eliminate <m>x_2</m> from the third equation:
        <me>
          \amat{
            1 2 3 6;
            0 -5 -10 -20;
            0 -7 -4 2
          } \quad\xrightarrow{R_3\minuseq\frac57 R_2}\quad
          \amat{
            1 2 3 6;
            0 -5 -10 -20;
            0 \textcolor{seq-red}0 10 30
          }.
        </me>
        The elimination procedure has now finished.  We translate our augmented matrix back into a system of equations:
        <me>
          \amat{
            1 2 3 6;
            0 -5 -10 -20;
            0 0 10 30
          }\quad\xrightarrow{\text{becomes}}\quad
          \syseq{
            x_1 + 2x_2 + 3x_3 = 6;
            \. - 5x_2 - 10x_3 = -20;
            \. \+ \. \+ 10x_3 = 30
          }
        </me>
        and solve this system using back-substitution as before.
      </p>
    </example>

    <definition xml:id="def-row-equivalence">
      <idx><h>Row equivalence</h></idx>
      <statement>
        <p>Two matrices are called <term>row equivalent</term> if one can be obtained from the other by doing some number of row operations.</p>
      </statement>
    </definition>

    <p>
      According to this <xref ref="row-ops-same-soln-set"/>, if two augmented matrices are row equivalent, then the corresponding systems of equations have the <em>same solution set</em>.
    </p>

  </subsection>

</section>
